[TOC]

# Introduction

We are a three person team (group 34) and we built a database system called AwesomeDB. We designed different database engine for our database system that provides support for relational and nosql functionalities. We provided two real-life large datasets form kaggle, `movies.csv` and `rotten_tomatoes_movies.csv` for testing our databases. Since the two data set doesn't have tables to be joined, we also supplied the `joinTable1.csv` and `joinTable2.csv` for testing join operations. All storage and operations are processed in chunks so that we only need to load a limited amount of data into main memory at a time. This project also provides a CLI and Web app for users to interact with our database system. We also designed a query language of our own to query the database in the CLI.

# Planned Implementation

# Architecture Design

## Flow Diagram

![image-20231208150246901](img/image-20231208150246901.png)

## Modules Description

```bash
.
├── Engine                  # The database engines
│   ├── base.py             # The abstract base engine
│   ├── nosql.py            # The NoSQL engine: implements all NoSQL operations
│   └── relational.py       # The relational engine: all relational operations
├── Results                 # The results generated by backend, send to frontend
│   └── result.txt
├── Storage                 # Stores all table data
│   ├── NoSQL               # Storage for NoSQL, each subdir is a table
│   │   ├── table_1
│   │   │   ├── chunk_1     # chunks for table_1 in NoSQL DB
│   │   │   ├── chunk_2
│   │   │   ...
│   │   ├── table_2         # Another table in NoSQL DB
│   │   │
│   │   ...
│   └── Relational          # Storage for Relational, each subdir is a table
│   │   ├── table_1
│   │   │   ├── chunk_1     # chunks for table_1 in relational DB
│   │   │   ├── chunk_2
│   │   │   ├── schema.txt  # Relational tables have schemas
│   │   │   ...
│   │   ├── table_2         # Another table in relational DB
│   │   │
│   │   ...
├── Temp                    # For temporary data during processing
├── ToBeLoaded              # Put datasets (.csv) to be loaded in this directory
│   └── movies.csv          # A dataset that can be loaded into Storage
├── config.py               # Configs of this system
├── main.py                 # Entry of the CLI
├── run.py                  # Starts the web server
├── static                  # Static data of the web server
│   ├── index.html
│   └── script.js
├── utils                   # Utility functions/Class during processing
│   ├── DocElement.py
│   ├── RowElement.py
│   ├── util.py
│
...
```

# Implementation

## Storage and Chunking

We store all data loaded in our database under the the `/Storage` directory.

```bash
.
├── Storage                 # Stores all table data
│   ├── NoSQL               # Storage for NoSQL, each subdir is a table
│   │   ├── table_1
│   │   │   ├── chunk_1     # chunks for table_1 in NoSQL DB
│   │   │   ├── chunk_2
│   │   │   ...
│   │   ├── table_2         # Another table in NoSQL DB
│   │   │
│   │   ...
│   └── Relational          # Storage for Relational, each subdir is a table
│   │   ├── table_1
│   │   │   ├── chunk_1     # chunks for table_1 in relational DB
│   │   │   ├── chunk_2
│   │   │   ├── schema.txt  # Relational tables have schemas
│   │   │   ...
│   │   ├── table_2         # Another table in relational DB
│   │   │
│   │   ...
```

<img src="img/image-20231208154127959.png" alt="image-20231208154127959" style="zoom:50%;" />

Once a dataset is loaded into our database, it is stored in chunks. To load a database, it is first stored/uploaded by the user to the `/ToBeLoaded` directory. Then, the database engine calls the `load_data()` which calls the `_insert_row()` or `_insert_doc()` function. This function detects if the chunk with largest chunk number is full. If it is not full, we insert the row/doc into that chunk, otherwise, we have to create a new chunk and store the new row/doc in that chunk. Once a user inserts a new data the engine also calls the `_insert_row()` or `_insert_doc()` function.

For relational data, we store the chunks as `.csv` files. We also have a `schema.txt` for each table to record the schema and data types of each row.

For NoSQL storage, all data are stored as JSON docs. Therefore, we don't store the chunks as `.csv` but as a text file with no file extension. Each line in the chunks is a string that can be deserialized into JSON docs.

Following is a screenshots of the `_insert_row()` function.

![image-20231208155429465](img/image-20231208155429465.png)

## CLI

Use `python3 main.py` to start a CLI of our program. Follow the prompt to type queries.

<img src="img/image-20231208160707599.png" alt="image-20231208160707599" style="zoom:50%;" />

Our queries are parsed and validated using regular expression. The keywords in the queries are extracted in the `parse_and_execute()` function in the `BaseEngine` class and passed to execution functions. Following is a screenshot of the regular expression of our queries.

![image-20231208162438113](img/image-20231208162438113.png)

## Web App

We use Flask for backend and serves the `/static/index.html` as static files to our user. The `index.html` are styled using Bootstrap. The `/static/script.js` is linked with the page and it uses `async/await` with fetch API to make HTTP POST request to the backend and receives the result file and display the content in the result display section.

To start the backend server, run `python3 run.py`. Use a web browser to navigate to the index page hosted our local server.

Following is a screenshot of the web page and the query result of showing the fields `name,rating` from the movies dataset.

![image-20231208163326194](img/image-20231208163326194.png)

<img src="img/image-20231208163337679.png" alt="image-20231208163337679" style="zoom:50%;" />

The backend receives the HTTP request and choose the corresponding database engine to execute the query. Then it sends back a result file to the front end. Following is a description of the web backend function to filter data.

![image-20231208181326152](img/image-20231208181326152.png)

## 



# Learning Outcomes

# Individual Contribution

# Conclusion

# Future Scope